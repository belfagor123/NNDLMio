{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bebbc3-11b6-4963-9d9e-140b9e094675",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a4dcce0-2260-4b80-ae7f-42f5dd6c081d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "from torchvision.models import Inception_V3_Weights\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class InceptionTrainer:\n",
    "    def __init__(self, num_classes=10, pretrained=True, freeze_features=True):\n",
    "        self.num_classes = num_classes\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = self._build_model(pretrained, freeze_features).to(self.device)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = None  # To be set later\n",
    "\n",
    "    def _build_model(self, pretrained, freeze_features):\n",
    "        # Use the new weights parameter\n",
    "        weights = Inception_V3_Weights.IMAGENET1K_V1 if pretrained else None\n",
    "        # Load the model with aux_logits set to True\n",
    "        model = models.inception_v3(weights=weights, aux_logits=True)\n",
    "        if freeze_features:\n",
    "            for param in model.parameters():\n",
    "                param.requires_grad = False\n",
    "        # Modify the final classification layer\n",
    "        model.fc = nn.Linear(model.fc.in_features, self.num_classes)\n",
    "\n",
    "        return model\n",
    "\n",
    "    def set_optimizer(self, lr=0.001, optimizer_type='SGD', momentum=0.9):\n",
    "        \"\"\"Sets the optimizer.\"\"\"\n",
    "        if optimizer_type == 'SGD':\n",
    "            self.optimizer = torch.optim.SGD(\n",
    "                filter(lambda p: p.requires_grad, self.model.parameters()),\n",
    "                lr=lr,\n",
    "                momentum=momentum\n",
    "            )\n",
    "        elif optimizer_type == 'Adam':\n",
    "            self.optimizer = torch.optim.Adam(\n",
    "                filter(lambda p: p.requires_grad, self.model.parameters()),\n",
    "                lr=lr\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported optimizer type. Choose 'SGD' or 'Adam'.\")\n",
    "\n",
    "    def train(self, trainloader, epochs=5):\n",
    "        \"\"\"Trains the model.\"\"\"\n",
    "        self.model.train()\n",
    "        for epoch in range(epochs):\n",
    "            running_loss = 0.0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for inputs, labels in trainloader:\n",
    "                inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "                self.optimizer.zero_grad()\n",
    "                outputs = self.model(inputs)  # Outputs logits and aux_logits\n",
    "\n",
    "                # Compute the loss using both primary and auxiliary logits\n",
    "                main_loss = self.criterion(outputs.logits, labels)\n",
    "                aux_loss = self.criterion(outputs.aux_logits, labels)\n",
    "                loss = main_loss + 0.4 * aux_loss\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "\n",
    "                # Get predictions from primary logits for accuracy calculation\n",
    "                _, predicted = torch.max(outputs.logits, 1)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "\n",
    "            print(f\"Epoch {epoch + 1}/{epochs}, Loss: {running_loss / len(trainloader):.4f}, \"\n",
    "                  f\"Accuracy: {100 * correct / total:.2f}%\")\n",
    "\n",
    "    def evaluate(self, testloader):\n",
    "        \"\"\"Evaluates the model.\"\"\"\n",
    "        self.model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in testloader:\n",
    "                inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "                outputs = self.model(inputs)  # Outputs logits and aux_logits\n",
    "                \n",
    "                # Get predictions from primary logits\n",
    "                _, predicted = torch.max(outputs.logits, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b873bb3e-4f89-49f5-a0e2-3f06533d6a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "from torchvision.models import Inception_V3_Weights\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, reduction='mean'):\n",
    "        \"\"\"\n",
    "        Custom implementation of focal loss.\n",
    "        alpha: weight factor for the class (default is balanced across classes).\n",
    "        gamma: focusing parameter that reduces the loss for well-classified examples.\n",
    "        reduction: specifies the reduction to apply to the output ('none', 'mean', or 'sum').\n",
    "        \"\"\"\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = nn.CrossEntropyLoss(reduction='none')(inputs, targets)  # Cross-entropy per sample\n",
    "        pt = torch.exp(-ce_loss)  # Probability of the true class\n",
    "        focal_loss = self.alpha * ((1 - pt) ** self.gamma) * ce_loss\n",
    "        \n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss\n",
    "\n",
    "\n",
    "class InceptionTrainer:\n",
    "    def __init__(self, num_classes=10, pretrained=True, freeze_features=True, loss_type='cross_entropy', focal_params=None):\n",
    "        \"\"\"\n",
    "        Initialize InceptionTrainer.\n",
    "        \n",
    "        num_classes: number of output classes.\n",
    "        pretrained: whether to use pre-trained weights.\n",
    "        freeze_features: whether to freeze feature extraction layers.\n",
    "        loss_type: specify 'cross_entropy' or 'focal' for the loss function.\n",
    "        focal_params: dictionary to configure FocalLoss (e.g., {'alpha': 1, 'gamma': 2}).\n",
    "        \"\"\"\n",
    "        self.num_classes = num_classes\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = self._build_model(pretrained, freeze_features).to(self.device)\n",
    "        self.optimizer = None\n",
    "        self.loss_type = loss_type.lower()\n",
    "        self.focal_params = focal_params or {}\n",
    "\n",
    "        # Set loss function\n",
    "        if self.loss_type == 'cross_entropy':\n",
    "            self.criterion = nn.CrossEntropyLoss()\n",
    "        elif self.loss_type == 'focal':\n",
    "            self.criterion = FocalLoss(**self.focal_params)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid loss_type. Choose 'cross_entropy' or 'focal'.\")\n",
    "\n",
    "    def _build_model(self, pretrained, freeze_features):\n",
    "        weights = Inception_V3_Weights.IMAGENET1K_V1 if pretrained else None\n",
    "        model = models.inception_v3(weights=weights, aux_logits=True)\n",
    "        if freeze_features:\n",
    "            for param in model.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        model.fc = nn.Sequential(\n",
    "            nn.Linear(model.fc.in_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, self.num_classes)\n",
    "        )\n",
    "\n",
    "        return model\n",
    "\n",
    "    def set_optimizer(self, lr=0.001, optimizer_type='SGD', momentum=0.9):\n",
    "        \"\"\"Sets the optimizer.\"\"\"\n",
    "        if optimizer_type == 'SGD':\n",
    "            self.optimizer = torch.optim.SGD(filter(lambda p: p.requires_grad, self.model.parameters()), lr=lr, momentum=momentum)\n",
    "        elif optimizer_type == 'Adam':\n",
    "            self.optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, self.model.parameters()), lr=lr)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported optimizer type. Choose 'SGD' or 'Adam'.\")\n",
    "\n",
    "    def train(self, trainloader, epochs=5):\n",
    "        \"\"\"Trains the model.\"\"\"\n",
    "        self.model.train()\n",
    "        for epoch in range(epochs):\n",
    "            running_loss = 0.0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for inputs, labels in trainloader:\n",
    "                inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "                self.optimizer.zero_grad()\n",
    "                outputs = self.model(inputs)\n",
    "                outputs = outputs.logits\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "\n",
    "            print(f\"Epoch {epoch + 1}/{epochs}, Loss: {running_loss/len(trainloader):.4f}, Accuracy: {100 * correct / total:.2f}%\")\n",
    "\n",
    "    def evaluate(self, testloader):\n",
    "        \"\"\"Evaluates the model.\"\"\"\n",
    "        self.model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in testloader:\n",
    "                inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                outputs = outputs.logits\n",
    "\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ce1b4de-ee6b-46e6-abf1-269fd898d2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridTrainer:\n",
    "    def __init__(self, num_classes=10, pretrained=True, freeze_features=True):\n",
    "        self.num_classes = num_classes\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = self._build_model(pretrained, freeze_features).to(self.device)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = None  # To be set later\n",
    "\n",
    "    def _build_model(self, pretrained, freeze_features):\n",
    "        weights_resnet = ResNet18_Weights.IMAGENET1K_V1 if pretrained else None\n",
    "        resnet = models.resnet18(weights=weights_resnet)\n",
    "        if freeze_features:\n",
    "            for param in resnet.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        inception = models.inception_v3(weights=None, aux_logits=False)  # Use inception without weights or aux_logits\n",
    "        resnet.fc = nn.Identity()  # Remove fully connected layer in ResNet18\n",
    "        hybrid_model = nn.Sequential(\n",
    "            resnet,\n",
    "            nn.Flatten(),  # Flatten output of ResNet for inception input\n",
    "            nn.Linear(resnet.fc.in_features, 512),\n",
    "            nn.ReLU(),\n",
    "            inception.fc,  # Reuse inception's FC layer\n",
    "        )\n",
    "        return hybrid_model\n",
    "\n",
    "    def set_optimizer(self, lr=0.001, optimizer_type='SGD', momentum=0.9):\n",
    "        if optimizer_type == 'SGD':\n",
    "            self.optimizer = torch.optim.SGD(filter(lambda p: p.requires_grad, self.model.parameters()), lr=lr, momentum=momentum)\n",
    "        elif optimizer_type == 'Adam':\n",
    "            self.optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, self.model.parameters()), lr=lr)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported optimizer type. Choose 'SGD' or 'Adam'.\")\n",
    "\n",
    "    def train(self, trainloader, epochs=5):\n",
    "        self.model.train()\n",
    "        for epoch in range(epochs):\n",
    "            running_loss = 0.0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for inputs, labels in trainloader:\n",
    "                inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "                self.optimizer.zero_grad()\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "            print(f\"Epoch {epoch + 1}/{epochs}, Loss: {running_loss/len(trainloader):.4f}, Accuracy: {100 * correct / total:.2f}%\")\n",
    "\n",
    "    def evaluate(self, testloader):\n",
    "        self.model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in testloader:\n",
    "                inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        print(f\"Test Accuracy: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64985bf9-572e-4238-920f-937bdfe70f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "\n",
    "class ResNet18Trainer:\n",
    "    def __init__(self, num_classes=10, pretrained=True, freeze_features=True):\n",
    "        \"\"\"\n",
    "        Initializes the ResNet18 model trainer.\n",
    "        Args:\n",
    "        - num_classes: Number of output classes.\n",
    "        - pretrained: Whether to use pretrained weights.\n",
    "        - freeze_features: Whether to freeze feature extractor layers.\n",
    "        \"\"\"\n",
    "        self.num_classes = num_classes\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = self._build_model(pretrained, freeze_features).to(self.device)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = None  # To be set later\n",
    "\n",
    "    def _build_model(self, pretrained, freeze_features):\n",
    "        \"\"\"\n",
    "        Builds the ResNet18 model with options to load pretrained weights and freeze features.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Attempt to use the new weights API for torchvision\n",
    "            weights = models.ResNet18_Weights.IMAGENET1K_V1 if pretrained else None\n",
    "            model = models.resnet18(weights=weights)\n",
    "        except AttributeError:\n",
    "            # Fallback for older torchvision versions\n",
    "            model = models.resnet18(pretrained=pretrained)\n",
    "        \n",
    "        if freeze_features:\n",
    "            for param in model.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        model.fc = nn.Sequential(\n",
    "            nn.Linear(model.fc.in_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, self.num_classes)\n",
    "        )\n",
    "        return model\n",
    "\n",
    "    def set_optimizer(self, lr=0.001, optimizer_type='SGD', momentum=0.9):\n",
    "        \"\"\"\n",
    "        Sets the optimizer for training.\n",
    "        Args:\n",
    "        - lr: Learning rate.\n",
    "        - optimizer_type: Type of optimizer ('SGD' or 'Adam').\n",
    "        - momentum: Momentum factor (for SGD only).\n",
    "        \"\"\"\n",
    "        if optimizer_type == 'SGD':\n",
    "            self.optimizer = torch.optim.SGD(filter(lambda p: p.requires_grad, self.model.parameters()), \n",
    "                                             lr=lr, momentum=momentum,weight_decay=0.0001)\n",
    "        elif optimizer_type == 'Adam':\n",
    "            self.optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, self.model.parameters()), \n",
    "                                              lr=lr, weight_decay=0.0001)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported optimizer type. Choose 'SGD' or 'Adam'.\")\n",
    "\n",
    "    def train(self, trainloader, epochs=5):\n",
    "        \"\"\"\n",
    "        Trains the model.\n",
    "        Args:\n",
    "        - trainloader: Dataloader for the training dataset.\n",
    "        - epochs: Number of epochs to train.\n",
    "        \"\"\"\n",
    "        self.model.train()\n",
    "        for epoch in range(epochs):\n",
    "            running_loss = 0.0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "\n",
    "            for inputs, labels in trainloader:\n",
    "                inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ac07b2e-3c80-4de6-b3c6-63c4b44a2828",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import auxiliaries as aux\n",
    "import os \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import os\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "#from torchinfo import summary\n",
    "import time\n",
    "import auxiliaries as aux\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  \n",
    "\n",
    "# Define parameters\n",
    "classification_type = 'make'  # Make or model\n",
    "num_epochs = 25\n",
    "batch_size = 32\n",
    "learning_rate = 1e-4\n",
    "splits_folder='train_test_split_full_make_100_80_20_0'  # Folder which contains two files train.txt and test.txt with a list of images to use for train and test\n",
    "#model_name='inceptionmodified'  # Model, for now between inception, resnet18 and resnet-simple                     \n",
    "loss_name='focal'   # Loss, for now between focal and cross-entropy\n",
    "patience = 4    # For early stopping\n",
    "progressive = 5 # Used for differentiating between runs with same parameters\n",
    "use_data_augmentation=False\n",
    "\n",
    "image_type=splits_folder.split('_')[3]\n",
    "\n",
    "# Name the file where we save the model with the parameters used for better readability\n",
    "#model_save_name=f'model_{model_name}_{classification_type}_{batch_size}_{loss_name}_{progressive}.pt'\n",
    "\n",
    "# Define root path (where the images are) and train path (where the list of images to use is)\n",
    "root_dir = os.path.join(os.getcwd(), f'../CompCars/data/{'cropped_image' if image_type=='full' else 'part'}')\n",
    "file_paths_train = os.path.join(os.getcwd(), f'../CompCars/data/splits/{splits_folder}/classification/train.txt')\n",
    "root_dir = os.path.join(os.getcwd(),\n",
    "                          f\"C:\\\\Users\\\\Utilisateur\\\\Desktop\\\\DL\\\\datasets\\\\data\\\\data\\\\{'cropped_image' if image_type=='full' else 'part'}\")     # Root path of where the images are\n",
    "file_paths_train = os.path.join(os.getcwd(),\n",
    "                           f\"C:\\\\Users\\\\Utilisateur\\\\Desktop\\\\DL\\\\datasets\\\\data\\\\data\\\\splits\\\\{splits_folder}\\\\classification\\\\train.txt\")  \n",
    "\n",
    "# Set number of classes\n",
    "if classification_type == 'make':\n",
    "    if image_type=='full':\n",
    "        num_classes = 163\n",
    "    elif image_type=='part':\n",
    "        num_classes = 123\n",
    "elif classification_type == 'model':\n",
    "    if image_type == 'full':    \n",
    "        num_classes = 1716\n",
    "    elif image_type == 'part':\n",
    "        num_classes = 956\n",
    "else:\n",
    "    print('Wrong classification type') \n",
    "\n",
    "\n",
    "# Define transformations (resize was arbitrary, normalize was requested from pytorch)\n",
    "if use_data_augmentation==False:\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((299, 299)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "else:\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((299, 299)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.05),\n",
    "        transforms.RandomPerspective(distortion_scale=0.2, p=0.5),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.RandomErasing(p=0.3, scale=(0.02, 0.1), ratio=(0.3, 3.3)),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "# Create custom dataset\n",
    "dataset = aux.ClassificationImageDataset(root_dir=root_dir, file_paths=file_paths_train, \n",
    "                                 classification_type=classification_type, \n",
    "                                 transform=transform, train=True, validation_split=0.25)\n",
    "\n",
    "# Create training and validation subsets using the indices calculated during dataset.__init__()\n",
    "train_subset = Subset(dataset, dataset.train_indices)\n",
    "val_subset = Subset(dataset, dataset.val_indices)\n",
    "\n",
    "# Create dataloaders for training and validation\n",
    "train_loader = DataLoader(train_subset, batch_size=batch_size)\n",
    "#valid_loader = DataLoader(val_subset, batch_size=batch_size)\n",
    "#testloader = DataLoader(testset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10384da5-f45a-4380-a221-c8c5260d0426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 4.3090, Accuracy: 5.88%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Instantiate the model trainer\n",
    "inception_trainer = InceptionTrainer(num_classes=num_classes, pretrained=True, freeze_features=True)\n",
    "\n",
    "# Set up optimizer\n",
    "inception_trainer.set_optimizer(lr=0.001, optimizer_type='Adam')\n",
    "\n",
    "# Train the model\n",
    "inception_trainer.train(train_loader, epochs=5)\n",
    "\n",
    "# Evaluate the model\n",
    "#inception_trainer.evaluate(testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a8aca1-d2d1-4b16-abcd-661cffc7b159",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Instantiate the model trainer\n",
    "Res_trainer = ResNet18Trainer(num_classes=num_classes, pretrained=True, freeze_features=True)\n",
    "\n",
    "# Set up optimizer\n",
    "Res_trainer.set_optimizer(lr=0.001, optimizer_type='Adam')\n",
    "\n",
    "# Train the model\n",
    "Res_trainer.train(train_loader, epochs=5)\n",
    "\n",
    "# Evaluate the model\n",
    "#Res_trainer.evaluate(testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccee5f9a-c0f5-4adf-8dc7-3bde3fd86ca0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79089a0-300c-40da-8604-6656a45f6575",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070960e7-fc6a-40c7-9544-49f2e1a9615c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e594df-d226-4f09-bc3e-35e5c00ad87f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
